"""
Finansal Agentic Proje LangGraph Workflow
=========================================

Bu modÃ¼l LangGraph'in gerÃ§ek gÃ¼cÃ¼nÃ¼ kullanarak finansal agent'larÄ±n workflow'unu yÃ¶netir.
LangGraph'in multi-agent sistem mimarisi ile PaymentsAgent, RiskAgent, InvestmentAgent
ve CoordinatorAgent'larÄ± koordine eder.

LangGraph Ã–zellikleri:
- StateGraph: Agent'lar arasÄ± state yÃ¶netimi
- Tool Calling: Agent'larÄ±n MCP araÃ§larÄ±nÄ± kullanmasÄ±
- Conditional Routing: Dinamik akÄ±ÅŸ kontrolÃ¼
- Memory Management: Redis + Qdrant entegrasyonu
- Error Handling: Hata durumlarÄ±nda fallback mekanizmalarÄ±
- GerÃ§ek Ollama LLM: llama3.2:1b model'i ile gerÃ§ek LLM Ã§aÄŸrÄ±larÄ±
- MCP Tool Calling: Fallback sistem ile MCP araÃ§larÄ± entegrasyonu

Workflow AkÄ±ÅŸÄ±:
1. PaymentsAgent: MaaÅŸ yatÄ±ÅŸÄ±nÄ± analiz eder ve transfer Ã¶nerisi yapar
2. RiskAgent: Ä°ÅŸlem riskini deÄŸerlendirir
3. InvestmentAgent: Risk profiline gÃ¶re yatÄ±rÄ±m Ã¶nerileri sunar
4. CoordinatorAgent: TÃ¼m bilgileri birleÅŸtirerek final mesaj oluÅŸturur
5. UserInteraction: KullanÄ±cÄ± etkileÅŸimi ve onay sÃ¼reci
6. Execution: Onaylanan iÅŸlemlerin gerÃ§ekleÅŸtirilmesi

Son GÃ¼ncellemeler (2025-09-16):
- GerÃ§ek Ollama llama3.2:1b model'i entegrasyonu
- Bellek optimizasyonu (llama3.2:3b â†’ llama3.2:1b)
- Timeout iyileÅŸtirmeleri (30s â†’ 120s)
- MCP Tool Calling fallback sistemi
- Manuel HTTP istekleri ile Ollama entegrasyonu
"""

import time
import json
from typing import TypedDict, Dict, Any, Optional, List, Literal
from queue import Queue
from langchain_core.tools import tool
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langchain_ollama import ChatOllama
from langgraph.graph import StateGraph, END, START
from langgraph.checkpoint.memory import MemorySaver
from langgraph.prebuilt import ToolNode, tools_condition

from config import config
from services import service_manager


class FinancialState(TypedDict):
    """
    LangGraph workflow state tanÄ±mÄ± - LangGraph'in gerÃ§ek state yapÄ±sÄ±
    
    LangGraph'te state, mesajlar ve verilerin birleÅŸimidir. Bu state:
    - messages: Agent'lar arasÄ± iletiÅŸim iÃ§in mesaj listesi
    - data: Workflow boyunca taÅŸÄ±nan veriler
    - current_step: Hangi adÄ±mda olduÄŸumuzu takip eder
    - user_action: KullanÄ±cÄ± etkileÅŸimi sonucu
    - error: Hata durumlarÄ± iÃ§in
    """
    # LangGraph mesaj sistemi
    messages: List[HumanMessage | AIMessage | SystemMessage]
    
    # Workflow verileri
    userId: str
    amount: int
    correlationId: str
    
    # Agent Ã§Ä±ktÄ±larÄ±
    payments_output: Optional[Dict[str, Any]]
    risk_output: Optional[Dict[str, Any]]
    investment_output: Optional[Dict[str, Any]]
    coordinator_output: Optional[Dict[str, Any]]
    
    # KullanÄ±cÄ± etkileÅŸimi
    user_action: Optional[str]  # "approve", "reject", "custom_message"
    custom_message: Optional[str]
    
    # Workflow kontrolÃ¼
    current_step: str
    error: Optional[str]
    final_result: Optional[Dict[str, Any]]


class FinancialWorkflow:
    """
    Finansal agent'larÄ±n LangGraph workflow'unu yÃ¶neten ana sÄ±nÄ±f
    
    Bu sÄ±nÄ±f LangGraph'in gerÃ§ek multi-agent sistem mimarisini implement eder:
    - Her agent bir LangGraph node'u olarak tanÄ±mlanÄ±r
    - Agent'lar arasÄ± iletiÅŸim mesaj sistemi ile yapÄ±lÄ±r
    - Tool calling ile MCP araÃ§larÄ± kullanÄ±lÄ±r
    - Conditional routing ile dinamik akÄ±ÅŸ kontrolÃ¼
    - Memory management ile Redis + Qdrant entegrasyonu
    - GerÃ§ek Ollama llama3.2:1b model'i ile LLM Ã§aÄŸrÄ±larÄ±
    - Fallback sistem ile MCP tool calling
    
    Son GÃ¼ncellemeler (2025-09-16):
    - Bellek optimizasyonu: llama3.2:3b â†’ llama3.2:1b
    - Timeout iyileÅŸtirmeleri: 30s â†’ 120s
    - Manuel HTTP istekleri ile Ollama entegrasyonu
    - MCP Tool Calling fallback sistemi
    """
    
    def __init__(self, publisher_queue: Queue):
        """
        LangGraph workflow'unu baÅŸlatÄ±r
        
        Args:
            publisher_queue: Event yayÄ±nlama kuyruÄŸu (Kafka entegrasyonu iÃ§in)
        """
        self.publisher_queue = publisher_queue
        self.workflow = None
        
        # LangGraph iÃ§in gerekli araÃ§larÄ± tanÄ±mla
        self.tools = self._create_tools()
        
        # ========================================
        # LLM KONFÄ°GÃœRASYONU - Ã‡Ä°FT LLM MÄ°MARÄ°SÄ°
        # ========================================
        
        # ğŸ”¥ Ã–NEMLÄ°: Bu projede Ã§ift LLM mimarisi kullanÄ±lÄ±yor!
        # 
        # 1. GÃœÃ‡LÃœ LLM (Ollama llama3.2:3b - ngrok ile host edilen):
        #    - PaymentsAgent, RiskAgent, InvestmentAgent iÃ§in
        #    - Tool calling iÃ§in optimize edilmiÅŸ (3B parametre)
        #    - MCP araÃ§ Ã§aÄŸrÄ±larÄ± iÃ§in gÃ¼Ã§lÃ¼ analiz yeteneÄŸi
        #    - ngrok ile remote eriÅŸim, yÃ¼ksek performans
        #
        # 2. BÃœYÃœK LLM (Hugging Face deepseek-v3-0324):
        #    - CoordinatorAgent iÃ§in
        #    - RAG (Retrieval Augmented Generation) iÃ§in optimize edilmiÅŸ
        #    - Redis + Qdrant memory entegrasyonu
        #    - KiÅŸiselleÅŸtirilmiÅŸ final mesaj oluÅŸturma
        
        # Ollama LLM'i baÅŸlat (ngrok ile host edilen remote servis)
        # NOT: LangChain'in ChatOllama sÄ±nÄ±fÄ± container iÃ§inde baÄŸlantÄ± sorunu yaÅŸÄ±yor
        # Bu yÃ¼zden fallback olarak manuel HTTP istekleri kullanacaÄŸÄ±z
        self.ollama_model = config.OLLAMA_MODELS["LLM_MODEL"]  # llama3.2:3b - ngrok ile host edilen
        self.ollama_base_url = config.OLLAMA_BASE_URL  # http://localhost:11434
        
        # LangChain ChatOllama'yÄ± deneyelim, baÅŸarÄ±sÄ±z olursa fallback kullanacaÄŸÄ±z
        try:
            # Ollama client'Ä±nÄ± doÄŸrudan test et
            import ollama
            
            # Ollama client'Ä±nÄ± test et
            client = ollama.Client(host=self.ollama_base_url)
            test_response = client.chat(
                model=self.ollama_model,
                messages=[{"role": "user", "content": "Test mesajÄ±"}]
            )
            print(f"âœ… Ollama client test baÅŸarÄ±lÄ±: {test_response['message']['content'][:50]}...")
            
            # LangChain ChatOllama'yÄ± oluÅŸtur
            self.llm = ChatOllama(
                model=self.ollama_model,
                base_url=self.ollama_base_url,
                temperature=0.1,
                request_timeout=60.0,
                num_ctx=2048
            )
            print("âœ… ChatOllama baÅŸarÄ±yla oluÅŸturuldu")
            
            # Test Ã§aÄŸrÄ±sÄ± yap
            test_response = self.llm.invoke("Test mesajÄ±")
            print(f"âœ… ChatOllama test baÅŸarÄ±lÄ±: {test_response.content[:50]}...")
            
        except Exception as e:
            print(f"âš ï¸ ChatOllama oluÅŸturulamadÄ±: {e}")
            print("ğŸ”„ Fallback modu aktif - Manuel HTTP istekleri kullanÄ±lacak")
            self.llm = None
        
        print("ğŸ¤– LLM KonfigÃ¼rasyonu:")
        print(f"   ğŸ”¹ GÃ¼Ã§lÃ¼ LLM: Ollama llama3.2:3b (Agent'lar iÃ§in) - ngrok ile host edilen")
        print(f"   ğŸ”¹ BÃ¼yÃ¼k LLM: Hugging Face deepseek-v3-0324 (CoordinatorAgent iÃ§in)")
        print(f"   ğŸ”¹ Tool Calling: MCP Finance Tools entegrasyonu aktif")
        print(f"   ğŸ”¹ Embedding: nomic-embed-text:latest (RAG sistemi iÃ§in)")
        
        # Workflow'u oluÅŸtur
        self._create_langgraph_workflow()
    
    def _create_tools(self) -> List:
        """
        LangGraph iÃ§in MCP araÃ§larÄ±nÄ± tanÄ±mlar
        
        Bu araÃ§lar agent'larÄ±n MCP Finance Tools ile iletiÅŸim kurmasÄ±nÄ± saÄŸlar.
        Her araÃ§ LangChain tool formatÄ±nda tanÄ±mlanÄ±r.
        
        Returns:
            List: LangChain tool listesi
        """
        return [
            transactions_query,
            userProfile_get,
            risk_scoreTransaction,
            market_quotes,
            savings_createTransfer
        ]
    
    def _create_langgraph_workflow(self):
        """
        GerÃ§ek LangGraph workflow'unu oluÅŸturur
        
        Bu metod LangGraph'in tÃ¼m gÃ¼Ã§lÃ¼ Ã¶zelliklerini kullanÄ±r:
        - StateGraph: State yÃ¶netimi
        - ToolNode: AraÃ§ kullanÄ±mÄ±
        - Conditional routing: Dinamik akÄ±ÅŸ
        - Memory: Checkpointing
        """
        print("ğŸš€ LangGraph workflow oluÅŸturuluyor...")
        
        # StateGraph oluÅŸtur - LangGraph'in ana bileÅŸeni
        workflow = StateGraph(FinancialState)
        
        # ========================================
        # 1. AGENT NODE'LARI TANIMLA
        # ========================================
        
        # PaymentsAgent node'u - MaaÅŸ analizi ve transfer Ã¶nerisi
        workflow.add_node("payments_agent", self._payments_agent_node)
        
        # RiskAgent node'u - Risk analizi
        workflow.add_node("risk_agent", self._risk_agent_node)
        
        # InvestmentAgent node'u - YatÄ±rÄ±m Ã¶nerileri
        workflow.add_node("investment_agent", self._investment_agent_node)
        
        # CoordinatorAgent node'u - Final mesaj oluÅŸturma
        workflow.add_node("coordinator_agent", self._coordinator_agent_node)
        
        # UserInteraction node'u - KullanÄ±cÄ± etkileÅŸimi
        workflow.add_node("user_interaction", self._user_interaction_node)
        
        # Execution node'u - Ä°ÅŸlem gerÃ§ekleÅŸtirme
        workflow.add_node("execution", self._execution_node)
        
        # Tool node'u - MCP araÃ§larÄ±nÄ± kullanma
        tool_node = ToolNode(self.tools)
        workflow.add_node("tools", tool_node)
        
        # ========================================
        # 2. WORKFLOW AKIÅINI TANIMLA
        # ========================================
        
        # BaÅŸlangÄ±Ã§ noktasÄ±
        workflow.add_edge(START, "payments_agent")
        
        # SÄ±ralÄ± agent akÄ±ÅŸÄ±
        workflow.add_edge("payments_agent", "risk_agent")
        workflow.add_edge("risk_agent", "investment_agent")
        workflow.add_edge("investment_agent", "coordinator_agent")
        
        # Coordinator'dan sonra kullanÄ±cÄ± etkileÅŸimi
        workflow.add_edge("coordinator_agent", "user_interaction")
        
        # KullanÄ±cÄ± etkileÅŸiminden sonra koÅŸullu routing
        workflow.add_conditional_edges(
            "user_interaction",
            self._should_execute,
            {
                "execute": "execution",
                "end": END
            }
        )
        
        # Execution'dan sonra bitiÅŸ
        workflow.add_edge("execution", END)
        
        # ========================================
        # 3. WORKFLOW'U COMPILE ET
        # ========================================
        
        # Memory checkpointing ile compile et
        memory = MemorySaver()
        self.workflow = workflow.compile(checkpointer=memory)
        
        print("âœ… LangGraph workflow baÅŸarÄ±yla oluÅŸturuldu")
        print("ğŸ“‹ Node'lar: payments_agent â†’ risk_agent â†’ investment_agent â†’ coordinator_agent â†’ user_interaction â†’ execution")
        print("ğŸ”§ AraÃ§lar: MCP Finance Tools entegrasyonu aktif")
        print("ğŸ§  Memory: Redis + Qdrant checkpointing aktif")
    
    def _payments_agent_node(self, state: FinancialState) -> FinancialState:
        """
        PaymentsAgent Node - LangGraph node implementasyonu
        
        Bu node LangGraph'in gerÃ§ek node yapÄ±sÄ±nÄ± kullanÄ±r:
        - State'i alÄ±r ve gÃ¼nceller
        - Mesaj sistemi ile iletiÅŸim kurar
        - Tool calling ile MCP araÃ§larÄ±nÄ± kullanÄ±r
        - Event publishing ile Kafka'ya bildirim gÃ¶nderir
        
        LangGraph Node Ã–zellikleri:
        - Input: FinancialState
        - Output: GÃ¼ncellenmiÅŸ FinancialState
        - Side Effects: Kafka event publishing
        """
        print("ğŸ”„ PaymentsAgent node Ã§alÄ±ÅŸÄ±yor...")
        
        try:
            # State'ten verileri al
            userId = state["userId"]
            amount = state["amount"]
            correlationId = state["correlationId"]
            
            # ========================================
            # 1. KULLANICI PROFÄ°LÄ°NÄ° ANALÄ°Z ET
            # ========================================
            
            # System mesajÄ± ile agent'a gÃ¶rev ver
            system_message = SystemMessage(content=f"""
Sen PaymentsAgent'sÄ±n. GÃ¶revin:
1. KullanÄ±cÄ± {userId} iÃ§in {amount:,}â‚º maaÅŸ yatÄ±ÅŸÄ±nÄ± analiz et
2. KullanÄ±cÄ± profilini ve tercihlerini incele
3. Otomatik tasarruf oranÄ±nÄ± hesapla
4. Transfer Ã¶nerisi oluÅŸtur

KullanabileceÄŸin araÃ§lar:
- user_profile_get: KullanÄ±cÄ± profilini al
- transactions_query: GeÃ§miÅŸ iÅŸlemleri sorgula
- savings_create_transfer: Transfer Ã¶nerisi oluÅŸtur

TÃ¼rkÃ§e yanÄ±t ver ve detaylÄ± analiz yap.
            """)
            
            # Human mesajÄ± ile gÃ¶revi baÅŸlat
            human_message = HumanMessage(content=f"""
KullanÄ±cÄ± {userId} iÃ§in {amount:,}â‚º maaÅŸ yatÄ±ÅŸÄ± analizi yap.
Ã–nce kullanÄ±cÄ± profilini al, sonra geÃ§miÅŸ iÅŸlemlerini incele.
Otomatik tasarruf oranÄ±nÄ± hesaplayarak transfer Ã¶nerisi oluÅŸtur.
            """)
            
            # MesajlarÄ± state'e ekle
            messages = state.get("messages", [])
            messages.extend([system_message, human_message])
            
            # ========================================
            # 2. LLM Ä°LE ANALÄ°Z YAP - OLLAMA LLaMA3.2:3B KULLANIMI
            # ========================================
            
            # ğŸ”¥ Ã–NEMLÄ°: Burada Ollama Ã¼zerinden llama3.2:3b modeli kullanÄ±lÄ±yor!
            # Bu gÃ¼Ã§lÃ¼ LLM (3B parametre) agent'larÄ±n tool calling yapmasÄ± iÃ§in optimize edilmiÅŸ
            # LangChain'in bind_tools() metodu ile MCP araÃ§larÄ± LLM'e baÄŸlanÄ±yor
            # LLM artÄ±k hangi araÃ§larÄ± kullanabileceÄŸini biliyor ve otomatik olarak Ã§aÄŸÄ±rÄ±yor
            
            print(f"ğŸ¤– PaymentsAgent: Ollama llama3.2:3b modeli ile analiz baÅŸlatÄ±lÄ±yor...")
            
            # ChatOllama varsa kullan, yoksa manuel HTTP isteÄŸi gÃ¶nder
            if self.llm:
                try:
                    response = self.llm.bind_tools(self.tools).invoke(messages)
                    print(f"âœ… ChatOllama baÅŸarÄ±lÄ±")
                except Exception as e:
                    print(f"âš ï¸ ChatOllama baÅŸarÄ±sÄ±z: {e}")
                    print(f"ğŸ”„ Manuel HTTP isteÄŸi gÃ¶nderiliyor...")
                    response_content = self._call_ollama_manual(messages)
                    # Mock response oluÅŸtur
                    # AIMessage zaten import edilmiÅŸ
                    response = AIMessage(content=response_content)
            else:
                print(f"ğŸ”„ Manuel HTTP isteÄŸi gÃ¶nderiliyor...")
                response_content = self._call_ollama_manual(messages)
                # Mock response oluÅŸtur
                # AIMessage zaten import edilmiÅŸ
                response = AIMessage(content=response_content)
            
            # ========================================
            # 3. MCP TOOL Ã‡AÄRILARI - LLM TOOL CALLING
            # ========================================
            
            # ğŸ”¥ Ã–NEMLÄ°: LLM'in tool Ã§aÄŸrÄ±larÄ± yapÄ±p yapmadÄ±ÄŸÄ±nÄ± kontrol et
            print(f"ğŸ” PaymentsAgent: LLM yanÄ±tÄ± alÄ±ndÄ±, tool Ã§aÄŸrÄ±larÄ± kontrol ediliyor...")
            print(f"ğŸ“‹ LLM yanÄ±tÄ±: {response.content[:200]}...")
            print(f"ğŸ“‹ Tool calls sayÄ±sÄ±: {len(response.tool_calls) if response.tool_calls else 0}")
            
            profile = None
            transactions = None
            
            if response.tool_calls:
                print(f"ğŸ¯ PaymentsAgent: {len(response.tool_calls)} adet MCP tool Ã§aÄŸrÄ±sÄ± tespit edildi!")
                
                # Tool Ã§aÄŸrÄ±larÄ±nÄ± gerÃ§ekleÅŸtir
                tool_results = []
                for i, tool_call in enumerate(response.tool_calls):
                    tool_name = tool_call["name"]
                    tool_args = tool_call["args"]
                    
                    print(f"ğŸ”§ PaymentsAgent: Tool #{i+1} Ã§aÄŸrÄ±lÄ±yor: {tool_name}")
                    print(f"ğŸ“¥ Tool args: {tool_args}")
                    
                    # MCP aracÄ±nÄ± Ã§aÄŸÄ±r
                    result = self._call_mcp_tool(tool_name, tool_args)
                    tool_results.append(f"{tool_name}: {result}")
                    
                    print(f"âœ… PaymentsAgent: Tool #{i+1} tamamlandÄ±: {tool_name}")
                    print(f"ğŸ“¤ Tool result: {str(result)[:200]}...")
                    
                    # SonuÃ§larÄ± sakla
                    if tool_name == "userProfile_get":
                        profile = result
                    elif tool_name == "transactions_query":
                        transactions = result
                
                # Tool sonuÃ§larÄ±nÄ± mesaj olarak ekle
                tool_message = AIMessage(content=f"Tool Ã§aÄŸrÄ±larÄ± tamamlandÄ±: {'; '.join(tool_results)}")
                messages.append(tool_message)
                
                print(f"ğŸ”„ PaymentsAgent: Final LLM yanÄ±tÄ± alÄ±nÄ±yor...")
                # Final yanÄ±tÄ± al
                final_response = self.llm.invoke(messages)
                messages.append(final_response)
                print(f"âœ… PaymentsAgent: Final LLM yanÄ±tÄ± alÄ±ndÄ±")
            else:
                print(f"âš ï¸ PaymentsAgent: LLM hiÃ§ tool Ã§aÄŸrÄ±sÄ± yapmadÄ±!")
                print(f"ğŸ¤” LLM yanÄ±tÄ±: {response.content[:200]}...")
                
                # Fallback: Manuel olarak gerekli tool'larÄ± Ã§aÄŸÄ±r
                print(f"ğŸ”„ PaymentsAgent: Fallback olarak manuel tool Ã§aÄŸrÄ±larÄ± yapÄ±lÄ±yor...")
                profile = self._call_mcp_tool("userProfile.get", {"userId": userId})
                transactions = self._call_mcp_tool("transactions.query", {
                    "userId": userId,
                    "since": "last30d",
                    "limit": 10
                })
                print(f"ğŸ“Š PaymentsAgent: Fallback tool Ã§aÄŸrÄ±larÄ± tamamlandÄ±")
            
            # ========================================
            # 4. PAYMENTS OUTPUT OLUÅTUR
            # ========================================
            
            # LLM tool Ã§aÄŸrÄ±larÄ±ndan veya fallback'ten gelen verileri kullan
            if profile is None:
                print(f"âš ï¸ PaymentsAgent: Profile bulunamadÄ±, varsayÄ±lan deÄŸerler kullanÄ±lÄ±yor")
                profile = {"savedPreferences": {"autoSavingsRate": 0.3}}
            
            auto_rate = profile.get("savedPreferences", {}).get("autoSavingsRate", 0.3)
            propose_amount = int(amount * auto_rate)
            
            print(f"ğŸ’° PaymentsAgent: Tasarruf oranÄ± hesaplandÄ±: {auto_rate} ({auto_rate*100}%)")
            print(f"ğŸ’° PaymentsAgent: Transfer miktarÄ± hesaplandÄ±: {propose_amount:,}â‚º")
            print(f"ğŸ’° PaymentsAgent: LLM tool calling {'baÅŸarÄ±lÄ±' if response.tool_calls else 'baÅŸarÄ±sÄ±z - fallback kullanÄ±ldÄ±'}")
            
            payments_output = {
                "agent": "PaymentsAgent",
                "action": "analyze_deposit",
                "proposal": {
                    "action": "propose_transfer",
                    "amount": propose_amount,
                    "from": "CHK001",
                    "to": "SV001",
                    "rate": auto_rate
                },
                "message": f"MaaÅŸÄ±n {amount:,}â‚º olarak hesabÄ±na geÃ§ti. Plan gereÄŸi {propose_amount:,}â‚º tasarrufa aktarÄ±labilir.",
                "analysis": {
                    "user_profile": profile,
                    "auto_savings_rate": auto_rate,
                    "proposed_amount": propose_amount
                }
            }
            
            # ========================================
            # 4. EVENT PUBLISHING
            # ========================================
            
            # Agent Ã§Ä±ktÄ±sÄ±nÄ± Kafka'ya gÃ¶nder
            payments_output["type"] = "agent-output"
            self.publisher_queue.put({"event": "agent-output", "data": payments_output})
            
            # Kafka'ya payments.pending event'i gÃ¶nder
            service_manager.kafka_service.publish_event(
                config.KAFKA_TOPICS["PAYMENTS_PENDING"],
                {
                    "userId": userId,
                    "proposal": payments_output["proposal"],
                    "correlationId": correlationId
                }
            )
            
            # ========================================
            # 5. STATE GÃœNCELLE
            # ========================================
            
            # State'i gÃ¼ncelle
            updated_state = {
                **state,
                "messages": messages,
                "payments_output": payments_output,
                "current_step": "payments_agent_completed"
            }
            
            print(f"âœ… PaymentsAgent node tamamlandÄ±: {propose_amount:,}â‚º transfer Ã¶nerisi")
            return updated_state
            
        except Exception as e:
            print(f"âŒ PaymentsAgent node hatasÄ±: {e}")
            return {
                **state,
                "error": f"PaymentsAgent hatasÄ±: {str(e)}",
                "current_step": "error"
            }
    
    def _risk_agent_node(self, state: FinancialState) -> FinancialState:
        """
        RiskAgent Node - LangGraph node implementasyonu
        
        Bu node risk analizi yapar ve LangGraph'in mesaj sistemi ile Ã§alÄ±ÅŸÄ±r.
        """
        print("ğŸ”„ RiskAgent node Ã§alÄ±ÅŸÄ±yor...")
        
        try:
            userId = state["userId"]
            correlationId = state["correlationId"]
            payments_output = state.get("payments_output", {})
            
            if not payments_output:
                raise ValueError("PaymentsAgent Ã§Ä±ktÄ±sÄ± bulunamadÄ±")
            
            proposal = payments_output.get("proposal", {})
            
            # ========================================
            # 1. RÄ°SK ANALÄ°ZÄ° YAP
            # ========================================
            
            # System mesajÄ± ile agent'a gÃ¶rev ver
            system_message = SystemMessage(content=f"""
Sen RiskAgent'sÄ±n. GÃ¶revin:
1. Transfer iÅŸleminin risk skorunu hesapla
2. Risk faktÃ¶rlerini analiz et
3. GÃ¼venlik durumunu deÄŸerlendir

KullanabileceÄŸin araÃ§lar:
- risk_score_transaction: Risk skorunu hesapla

TÃ¼rkÃ§e yanÄ±t ver ve risk analizini detaylandÄ±r.
            """)
            
            # Human mesajÄ± ile gÃ¶revi baÅŸlat
            human_message = HumanMessage(content=f"""
Transfer iÅŸlemi iÃ§in risk analizi yap:
- Amount: {proposal.get('amount', 0):,}â‚º
- Type: internal_transfer
- User: {userId}

Risk skorunu hesapla ve analiz et.
            """)
            
            # MesajlarÄ± state'e ekle
            messages = state.get("messages", [])
            messages.extend([system_message, human_message])
            
            # ========================================
            # 2. LLM Ä°LE RÄ°SK ANALÄ°ZÄ° - OLLAMA LLaMA3.2:3B KULLANIMI
            # ========================================
            
            # ğŸ”¥ Ã–NEMLÄ°: RiskAgent da Ollama llama3.2:3b modeli kullanÄ±yor!
            # Risk analizi iÃ§in MCP araÃ§larÄ±nÄ± (risk.scoreTransaction) Ã§aÄŸÄ±rmasÄ± bekleniyor
            
            print(f"ğŸ¤– RiskAgent: Ollama llama3.2:3b modeli ile risk analizi baÅŸlatÄ±lÄ±yor...")
            
            # ChatOllama varsa kullan, yoksa manuel HTTP isteÄŸi gÃ¶nder
            if self.llm:
                try:
                    response = self.llm.bind_tools(self.tools).invoke(messages)
                    print(f"âœ… ChatOllama baÅŸarÄ±lÄ±")
                except Exception as e:
                    print(f"âš ï¸ ChatOllama baÅŸarÄ±sÄ±z: {e}")
                    print(f"ğŸ”„ Manuel HTTP isteÄŸi gÃ¶nderiliyor...")
                    response_content = self._call_ollama_manual(messages)
                    # Mock response oluÅŸtur
                    # AIMessage zaten import edilmiÅŸ
                    response = AIMessage(content=response_content)
            else:
                print(f"ğŸ”„ Manuel HTTP isteÄŸi gÃ¶nderiliyor...")
                response_content = self._call_ollama_manual(messages)
                # Mock response oluÅŸtur
                # AIMessage zaten import edilmiÅŸ
                response = AIMessage(content=response_content)
            
            # ========================================
            # 3. MCP TOOL Ã‡AÄRILARI - LLM TOOL CALLING
            # ========================================
            
            # ğŸ”¥ Ã–NEMLÄ°: LLM'in tool Ã§aÄŸrÄ±larÄ± yapÄ±p yapmadÄ±ÄŸÄ±nÄ± kontrol et
            print(f"ğŸ” RiskAgent: LLM yanÄ±tÄ± alÄ±ndÄ±, tool Ã§aÄŸrÄ±larÄ± kontrol ediliyor...")
            print(f"ğŸ“‹ LLM yanÄ±tÄ±: {response.content[:200]}...")
            print(f"ğŸ“‹ Tool calls sayÄ±sÄ±: {len(response.tool_calls) if response.tool_calls else 0}")
            
            risk_result = None
            
            if response.tool_calls:
                print(f"ğŸ¯ RiskAgent: {len(response.tool_calls)} adet MCP tool Ã§aÄŸrÄ±sÄ± tespit edildi!")
                
                # Tool Ã§aÄŸrÄ±larÄ±nÄ± gerÃ§ekleÅŸtir
                tool_results = []
                for i, tool_call in enumerate(response.tool_calls):
                    tool_name = tool_call["name"]
                    tool_args = tool_call["args"]
                    
                    print(f"ğŸ”§ RiskAgent: Tool #{i+1} Ã§aÄŸrÄ±lÄ±yor: {tool_name}")
                    print(f"ğŸ“¥ Tool args: {tool_args}")
                    
                    # MCP aracÄ±nÄ± Ã§aÄŸÄ±r
                    result = self._call_mcp_tool(tool_name, tool_args)
                    tool_results.append(f"{tool_name}: {result}")
                    
                    print(f"âœ… RiskAgent: Tool #{i+1} tamamlandÄ±: {tool_name}")
                    print(f"ğŸ“¤ Tool result: {str(result)[:200]}...")
                    
                    # SonuÃ§larÄ± sakla
                    if tool_name == "risk_scoreTransaction":
                        risk_result = result
                
                # Tool sonuÃ§larÄ±nÄ± mesaj olarak ekle
                tool_message = AIMessage(content=f"Tool Ã§aÄŸrÄ±larÄ± tamamlandÄ±: {'; '.join(tool_results)}")
                messages.append(tool_message)
                
                print(f"ğŸ”„ RiskAgent: Final LLM yanÄ±tÄ± alÄ±nÄ±yor...")
                # Final yanÄ±tÄ± al
                final_response = self.llm.invoke(messages)
                messages.append(final_response)
                print(f"âœ… RiskAgent: Final LLM yanÄ±tÄ± alÄ±ndÄ±")
            else:
                print(f"âš ï¸ RiskAgent: LLM hiÃ§ tool Ã§aÄŸrÄ±sÄ± yapmadÄ±!")
                print(f"ğŸ¤” LLM yanÄ±tÄ±: {response.content[:200]}...")
                
                # Fallback: Manuel olarak risk skorunu hesapla
                print(f"ğŸ”„ RiskAgent: Fallback olarak manuel risk skoru hesaplanÄ±yor...")
                risk_result = self._call_mcp_tool("risk.scoreTransaction", {
                    "userId": userId,
                    "tx": {
                        "amount": proposal.get("amount", 0),
                        "type": "internal_transfer"
                    }
                })
                print(f"ğŸ“Š RiskAgent: Fallback risk skoru hesaplandÄ±")
            
            # ========================================
            # 4. RÄ°SK OUTPUT OLUÅTUR
            # ========================================
            
            # LLM tool Ã§aÄŸrÄ±larÄ±ndan veya fallback'ten gelen verileri kullan
            if risk_result is None:
                print(f"âš ï¸ RiskAgent: Risk result bulunamadÄ±, varsayÄ±lan deÄŸerler kullanÄ±lÄ±yor")
                risk_result = {"score": 0.5, "reason": "default", "factors": ["unknown"]}
            
            risk_score = risk_result.get("score", 0.5)
            
            print(f"ğŸ›¡ï¸ RiskAgent: Risk skoru hesaplandÄ±: {risk_score}")
            print(f"ğŸ›¡ï¸ RiskAgent: Risk seviyesi: {'dÃ¼ÅŸÃ¼k' if risk_score < 0.3 else 'orta' if risk_score < 0.7 else 'yÃ¼ksek'}")
            print(f"ğŸ›¡ï¸ RiskAgent: LLM tool calling {'baÅŸarÄ±lÄ±' if response.tool_calls else 'baÅŸarÄ±sÄ±z - fallback kullanÄ±ldÄ±'}")
            
            risk_output = {
                "agent": "RiskAgent",
                "action": "analyze_risk",
                "analysis": risk_result,
                "message": f"Ä°ÅŸlem gÃ¼venli, {'dÃ¼ÅŸÃ¼k' if risk_score < 0.5 else 'yÃ¼ksek'} riskli.",
                "risk_score": risk_score,
                "risk_level": "low" if risk_score < 0.3 else "medium" if risk_score < 0.7 else "high"
            }
            
            # ========================================
            # 4. EVENT PUBLISHING
            # ========================================
            
            # Agent Ã§Ä±ktÄ±sÄ±nÄ± Kafka'ya gÃ¶nder
            risk_output["type"] = "agent-output"
            self.publisher_queue.put({"event": "agent-output", "data": risk_output})
            
            # Kafka'ya risk.analysis event'i gÃ¶nder
            service_manager.kafka_service.publish_event(
                config.KAFKA_TOPICS["RISK_ANALYSIS"],
                {
                    "userId": userId,
                    "analysis": risk_result,
                    "correlationId": correlationId
                }
            )
            
            # ========================================
            # 5. STATE GÃœNCELLE
            # ========================================
            
            updated_state = {
                **state,
                "messages": messages,
                "risk_output": risk_output,
                "current_step": "risk_agent_completed"
            }
            
            print(f"âœ… RiskAgent node tamamlandÄ±: Risk skoru {risk_score}")
            return updated_state
            
        except Exception as e:
            print(f"âŒ RiskAgent node hatasÄ±: {e}")
            return {
                **state,
                "error": f"RiskAgent hatasÄ±: {str(e)}",
                "current_step": "error"
            }
    
    def _investment_agent_node(self, state: FinancialState) -> FinancialState:
        """InvestmentAgent Node - Risk bazlÄ± yatÄ±rÄ±m Ã¶nerileri"""
        print("ğŸ”„ InvestmentAgent node Ã§alÄ±ÅŸÄ±yor...")
        
        try:
            userId = state["userId"]
            correlationId = state["correlationId"]
            risk_output = state.get("risk_output", {})
            
            if not risk_output:
                raise ValueError("RiskAgent Ã§Ä±ktÄ±sÄ± bulunamadÄ±")
            
            risk_score = risk_output.get("risk_score", 0.5)
            
            # ========================================
            # 1. LLM Ä°LE YATIRIM ANALÄ°ZÄ° - OLLAMA LLaMA3.2:1B KULLANIMI
            # ========================================
            
            # ğŸ”¥ Ã–NEMLÄ°: InvestmentAgent da Ollama llama3.2:1b modeli kullanÄ±yor!
            # YatÄ±rÄ±m analizi iÃ§in MCP araÃ§larÄ±nÄ± (market.quotes) Ã§aÄŸÄ±rmasÄ± bekleniyor
            
            # System mesajÄ± ile agent'a gÃ¶rev ver
            system_message = SystemMessage(content=f"""
Sen InvestmentAgent'sÄ±n. GÃ¶revin:
1. Risk skoru {risk_score} olan kullanÄ±cÄ± iÃ§in yatÄ±rÄ±m Ã¶nerileri oluÅŸtur
2. Risk durumuna gÃ¶re uygun varlÄ±k tÃ¼rlerini belirle
3. Piyasa kotalarÄ±nÄ± sorgula ve analiz et

KullanabileceÄŸin araÃ§lar:
- market_quotes: Piyasa kotalarÄ±nÄ± al

Risk skoru {risk_score} iÃ§in uygun yatÄ±rÄ±m stratejisi belirle.
TÃ¼rkÃ§e yanÄ±t ver ve detaylÄ± analiz yap.
            """)
            
            # Human mesajÄ± ile gÃ¶revi baÅŸlat
            human_message = HumanMessage(content=f"""
Risk skoru {risk_score} olan kullanÄ±cÄ± iÃ§in yatÄ±rÄ±m analizi yap.
Risk durumuna gÃ¶re uygun varlÄ±k tÃ¼rlerini belirle ve piyasa kotalarÄ±nÄ± sorgula.
            """)
            
            # MesajlarÄ± state'e ekle
            messages = state.get("messages", [])
            messages.extend([system_message, human_message])
            
            print(f"ğŸ¤– InvestmentAgent: Ollama llama3.2:3b modeli ile yatÄ±rÄ±m analizi baÅŸlatÄ±lÄ±yor...")
            
            # ChatOllama varsa kullan, yoksa manuel HTTP isteÄŸi gÃ¶nder
            if self.llm:
                try:
                    response = self.llm.bind_tools(self.tools).invoke(messages)
                    print(f"âœ… ChatOllama baÅŸarÄ±lÄ±")
                except Exception as e:
                    print(f"âš ï¸ ChatOllama baÅŸarÄ±sÄ±z: {e}")
                    print(f"ğŸ”„ Manuel HTTP isteÄŸi gÃ¶nderiliyor...")
                    response_content = self._call_ollama_manual(messages)
                    # Mock response oluÅŸtur
                    # AIMessage zaten import edilmiÅŸ
                    response = AIMessage(content=response_content)
            else:
                print(f"ğŸ”„ Manuel HTTP isteÄŸi gÃ¶nderiliyor...")
                response_content = self._call_ollama_manual(messages)
                # Mock response oluÅŸtur
                # AIMessage zaten import edilmiÅŸ
                response = AIMessage(content=response_content)
            
            # ========================================
            # 2. MCP TOOL Ã‡AÄRILARI - DETAYLI LOGGING
            # ========================================
            
            print(f"ğŸ” InvestmentAgent: LLM yanÄ±tÄ± alÄ±ndÄ±, tool Ã§aÄŸrÄ±larÄ± kontrol ediliyor...")
            print(f"ğŸ“‹ LLM yanÄ±tÄ±: {response.content[:200]}...")
            print(f"ğŸ“‹ Tool calls sayÄ±sÄ±: {len(response.tool_calls) if response.tool_calls else 0}")
            
            quotes = {}
            if response.tool_calls:
                print(f"ğŸ¯ InvestmentAgent: {len(response.tool_calls)} adet MCP tool Ã§aÄŸrÄ±sÄ± tespit edildi!")
                
                # Tool Ã§aÄŸrÄ±larÄ±nÄ± gerÃ§ekleÅŸtir
                tool_results = []
                for i, tool_call in enumerate(response.tool_calls):
                    tool_name = tool_call["name"]
                    tool_args = tool_call["args"]
                    
                    print(f"ğŸ”§ InvestmentAgent: Tool #{i+1} Ã§aÄŸrÄ±lÄ±yor: {tool_name}")
                    print(f"ğŸ“¥ Tool args: {tool_args}")
                    
                    # MCP aracÄ±nÄ± Ã§aÄŸÄ±r
                    result = self._call_mcp_tool(tool_name, tool_args)
                    tool_results.append(f"{tool_name}: {result}")
                    
                    print(f"âœ… InvestmentAgent: Tool #{i+1} tamamlandÄ±: {tool_name}")
                    print(f"ğŸ“¤ Tool result: {str(result)[:200]}...")
                    
                    # Market quotes sonuÃ§larÄ±nÄ± sakla
                    if tool_name == "market_quotes":
                        asset_type = tool_args.get("assetType", "unknown")
                        quotes[asset_type] = result
                
                # Tool sonuÃ§larÄ±nÄ± mesaj olarak ekle
                tool_message = AIMessage(content=f"Tool Ã§aÄŸrÄ±larÄ± tamamlandÄ±: {'; '.join(tool_results)}")
                messages.append(tool_message)
                
                print(f"ğŸ”„ InvestmentAgent: Final LLM yanÄ±tÄ± alÄ±nÄ±yor...")
                # Final yanÄ±tÄ± al
                final_response = self.llm.invoke(messages)
                messages.append(final_response)
                print(f"âœ… InvestmentAgent: Final LLM yanÄ±tÄ± alÄ±ndÄ±")
            else:
                print(f"âš ï¸ InvestmentAgent: LLM hiÃ§ tool Ã§aÄŸrÄ±sÄ± yapmadÄ±!")
                print(f"ğŸ¤” LLM yanÄ±tÄ±: {response.content[:200]}...")
                
                # Fallback: Manuel olarak market quotes al
                print(f"ğŸ”„ InvestmentAgent: Fallback olarak manuel market quotes alÄ±nÄ±yor...")
                asset_types = ["bond", "equity", "fund"] if risk_score < 0.3 else ["bond", "savings"]
                for asset_type in asset_types:
                    quotes[asset_type] = self._call_mcp_tool("market.quotes", {
                        "assetType": asset_type,
                        "tenor": "1Y"
                    })
                    print(f"ğŸ“Š InvestmentAgent: Manuel {asset_type} quotes alÄ±ndÄ±")
            
            # LLM tool Ã§aÄŸrÄ±larÄ±ndan veya fallback'ten gelen verileri kullan
            asset_types = list(quotes.keys()) if quotes else ["bond", "equity", "fund"]
            
            print(f"ğŸ“ˆ InvestmentAgent: {len(asset_types)} yatÄ±rÄ±m tÃ¼rÃ¼ analiz edildi")
            print(f"ğŸ“ˆ InvestmentAgent: YatÄ±rÄ±m stratejisi: {'agresif' if risk_score < 0.3 else 'muhafazakar'}")
            print(f"ğŸ“ˆ InvestmentAgent: LLM tool calling {'baÅŸarÄ±lÄ±' if response.tool_calls else 'baÅŸarÄ±sÄ±z - fallback kullanÄ±ldÄ±'}")
            
            investment_output = {
                "agent": "InvestmentAgent",
                "action": "analyze_investment",
                "recommendation": quotes,
                "message": f"Risk durumuna gÃ¶re yatÄ±rÄ±m Ã¶nerileri: {', '.join(asset_types)}",
                "strategy": "aggressive" if risk_score < 0.3 else "conservative",
                "asset_types": asset_types
            }
        
            # Event publishing
            investment_output["type"] = "agent-output"
            self.publisher_queue.put({"event": "agent-output", "data": investment_output})
            
            service_manager.kafka_service.publish_event(
                config.KAFKA_TOPICS["INVESTMENTS_PROPOSAL"],
                {
                    "userId": userId,
                    "recommendation": quotes,
                    "correlationId": correlationId
                }
            )
            
            print(f"âœ… InvestmentAgent node tamamlandÄ±: {len(asset_types)} yatÄ±rÄ±m Ã¶nerisi")
            return {
                **state,
                "investment_output": investment_output,
                "current_step": "investment_agent_completed"
            }
            
        except Exception as e:
            print(f"âŒ InvestmentAgent node hatasÄ±: {e}")
            return {
                **state,
                "error": f"InvestmentAgent hatasÄ±: {str(e)}",
                "current_step": "error"
            }
    
    def _coordinator_agent_node(self, state: FinancialState) -> FinancialState:
        """CoordinatorAgent Node - Final mesaj oluÅŸturma ve memory entegrasyonu"""
        print("ğŸ”„ CoordinatorAgent node Ã§alÄ±ÅŸÄ±yor...")
        
        try:
            userId = state["userId"]
            amount = state["amount"]
            correlationId = state["correlationId"]
        
            # HafÄ±zalarÄ± al
            short_term_memory = self._get_short_term_memory(userId)
            long_term_memory = self._get_long_term_memory(userId, "deposit analysis")
        
            # ========================================
            # HUGGING FACE API Ä°LE FÄ°NAL MESAJ OLUÅTURMA
            # ========================================
            
            # ğŸ”¥ Ã–NEMLÄ°: CoordinatorAgent bÃ¼yÃ¼k LLM kullanÄ±yor!
            # Hugging Face API Ã¼zerinden deepseek-v3-0324 modeli (bÃ¼yÃ¼k LLM)
            # Bu model RAG (Retrieval Augmented Generation) iÃ§in optimize edilmiÅŸ
            # Redis + Qdrant memory'lerden gelen verilerle zenginleÅŸtirilmiÅŸ prompt
            
            print(f"ğŸ§  CoordinatorAgent: Hugging Face deepseek-v3-0324 modeli ile final mesaj oluÅŸturuluyor...")
            print(f"ğŸ“š Memory kullanÄ±mÄ±: Redis (kÄ±sa vadeli) + Qdrant (uzun vadeli)")
            
            # Prompt oluÅŸtur (RAG sistemi ile zenginleÅŸtirilmiÅŸ)
            prompt = self._build_coordinator_prompt(userId, amount, state, short_term_memory, long_term_memory)
            system_prompt = self._get_coordinator_system_prompt()
            
            # BÃ¼yÃ¼k LLM ile final mesaj oluÅŸtur
            llm_response = service_manager.huggingface_service.generate_response(system_prompt, prompt)
            final_message = llm_response.get("text", "Analiz tamamlandÄ±.")
        
            coordinator_output = {
                "agent": "CoordinatorAgent",
                "action": "create_final_message",
                "message": final_message,
                "memory_used": {
                    "short_term": short_term_memory,
                    "long_term": long_term_memory
                }
            }
            
            # Event publishing
            notification = {
                "type": "final_proposal",
                "userId": userId,
                "correlationId": correlationId,
                "message": final_message,
                "proposal": state.get("payments_output", {}).get("proposal", {})
            }
            
            self.publisher_queue.put({"event": "notification", "data": notification})
            
            service_manager.kafka_service.publish_event(
                config.KAFKA_TOPICS["ADVISOR_FINAL_MESSAGE"],
                notification
            )
        
            # HafÄ±zalarÄ± gÃ¼ncelle
            self._update_memories(userId, amount, correlationId, final_message)
            
            print("âœ… CoordinatorAgent node tamamlandÄ±: Final mesaj oluÅŸturuldu")
            return {
                **state,
                "coordinator_output": coordinator_output,
                "current_step": "coordinator_agent_completed"
            }
            
        except Exception as e:
            print(f"âŒ CoordinatorAgent node hatasÄ±: {e}")
            return {
                **state,
                "error": f"CoordinatorAgent hatasÄ±: {str(e)}",
                "current_step": "error"
            }
    
    def _user_interaction_node(self, state: FinancialState) -> FinancialState:
        """UserInteraction Node - KullanÄ±cÄ± etkileÅŸimi simÃ¼lasyonu"""
        print("ğŸ”„ UserInteraction node Ã§alÄ±ÅŸÄ±yor...")
        
        # Bu node gerÃ§ek uygulamada Web UI'dan gelen kullanÄ±cÄ± etkileÅŸimini bekler
        # Åimdilik varsayÄ±lan olarak "approve" yapÄ±yoruz
        
        user_action = "approve"  # GerÃ§ek uygulamada Web UI'dan gelir
        
        print(f"âœ… UserInteraction node tamamlandÄ±: KullanÄ±cÄ± eylemi '{user_action}'")
        return {
            **state,
            "user_action": user_action,
            "current_step": "user_interaction_completed"
        }
    
    def _execution_node(self, state: FinancialState) -> FinancialState:
        """Execution Node - Onaylanan iÅŸlemleri gerÃ§ekleÅŸtirme"""
        print("ğŸ”„ Execution node Ã§alÄ±ÅŸÄ±yor...")
        
        try:
            userId = state["userId"]
            correlationId = state["correlationId"]
            user_action = state.get("user_action", "approve")
            
            if user_action == "approve":
                # Transfer iÅŸlemini gerÃ§ekleÅŸtir
                payments_output = state.get("payments_output", {})
                proposal = payments_output.get("proposal", {})
                
                # Mock transfer execution
                transfer_result = {
                    "status": "completed",
                    "transactionId": f"tx_{correlationId}",
                    "amount": proposal.get("amount", 0),
                    "timestamp": int(time.time())
                }
                
                # Event publishing
                execution_event = {
                    "event": "payments.executed",
                    "payload": {
                        "userId": userId,
                        "transactionId": transfer_result["transactionId"],
                        "amount": transfer_result["amount"],
                        "status": "completed",
                        "timestamp": transfer_result["timestamp"]
                    }
                }
                
                self.publisher_queue.put({"event": "payments.executed", "data": execution_event})
                
                service_manager.kafka_service.publish_event(
                    config.KAFKA_TOPICS["PAYMENTS_EXECUTED"],
                    execution_event["payload"]
                )
                
                final_result = {
                    "status": "success",
                    "message": "Transfer baÅŸarÄ±yla tamamlandÄ±",
                    "execution": transfer_result
                }
                
            elif user_action == "reject":
                final_result = {
                    "status": "rejected",
                    "message": "TÃ¼m Ã¶neriler reddedildi"
                }
                
            else:  # custom_message
                final_result = {
                    "status": "custom_processed",
                    "message": "Ã–zel mesaj iÅŸlendi"
                }
            
            print(f"âœ… Execution node tamamlandÄ±: {final_result['status']}")
            return {
                **state,
                "final_result": final_result,
                "current_step": "execution_completed"
            }
            
        except Exception as e:
            print(f"âŒ Execution node hatasÄ±: {e}")
            return {
                **state,
                "error": f"Execution hatasÄ±: {str(e)}",
                "current_step": "error"
            }
    
    def _should_execute(self, state: FinancialState) -> str:
        """
        Conditional routing - Execution'a gidip gitmeyeceÄŸini belirler
        
        LangGraph'in conditional routing Ã¶zelliÄŸini kullanÄ±r.
        """
        user_action = state.get("user_action")
        
        if user_action in ["approve", "reject", "custom_message"]:
            return "execute"
        else:
            return "end"
    
    def execute(self, initial_state: FinancialState) -> Optional[FinancialState]:
        """
        LangGraph workflow'unu Ã§alÄ±ÅŸtÄ±rÄ±r
        
        Bu metod LangGraph'in gerÃ§ek invoke metodunu kullanÄ±r:
        - State management: LangGraph'in state yÃ¶netimi
        - Checkpointing: Memory ile checkpointing
        - Error handling: Hata durumlarÄ±nda graceful handling
        
        Args:
            initial_state: BaÅŸlangÄ±Ã§ state'i (LangGraph formatÄ±nda)
            
        Returns:
            FinancialState: Workflow sonucu
        """
        if not self.workflow:
            print("âŒ LangGraph workflow henÃ¼z oluÅŸturulmamÄ±ÅŸ")
            return None
        
        try:
            print(f"ğŸš€ LangGraph workflow baÅŸlatÄ±lÄ±yor: {initial_state['correlationId']}")
            
            # LangGraph'in gerÃ§ek invoke metodunu kullan
            config_dict = {"configurable": {"thread_id": initial_state["correlationId"]}}
            
            # Initial state'i LangGraph formatÄ±na Ã§evir
            langgraph_state = {
                "messages": initial_state.get("messages", []),
                "userId": initial_state["userId"],
                "amount": initial_state["amount"],
                "correlationId": initial_state["correlationId"],
                "payments_output": initial_state.get("payments_output"),
                "risk_output": initial_state.get("risk_output"),
                "investment_output": initial_state.get("investment_output"),
                "coordinator_output": initial_state.get("coordinator_output"),
                "user_action": initial_state.get("user_action"),
                "custom_message": initial_state.get("custom_message"),
                "current_step": initial_state.get("current_step", "start"),
                "error": initial_state.get("error"),
                "final_result": initial_state.get("final_result")
            }
            
            # Workflow'u Ã§alÄ±ÅŸtÄ±r
            result = self.workflow.invoke(langgraph_state, config=config_dict)
            
            print(f"âœ… LangGraph workflow tamamlandÄ±: {initial_state['userId']}")
            print(f"ğŸ“Š Final step: {result.get('current_step', 'unknown')}")
            
            return result
            
        except Exception as e:
            print(f"âŒ LangGraph workflow Ã§alÄ±ÅŸtÄ±rma hatasÄ±: {e}")
            return {
                **initial_state,
                "error": f"Workflow hatasÄ±: {str(e)}",
                "current_step": "error"
            }
    
    def _call_ollama_manual(self, messages: list) -> str:
        """
        Ollama'ya manuel HTTP isteÄŸi gÃ¶nder (ChatOllama baÅŸarÄ±sÄ±z olduÄŸunda fallback)
        
        Bu metod LangChain'in ChatOllama sÄ±nÄ±fÄ± container iÃ§inde baÄŸlantÄ± sorunu yaÅŸadÄ±ÄŸÄ±nda
        devreye girer. Manuel HTTP istekleri ile Ollama'ya baÄŸlanÄ±r ve gerÃ§ek LLM Ã§aÄŸrÄ±larÄ± yapar.
        
        Ã–zellikler:
        - llama3.2:3b model'i kullanÄ±r (ngrok ile host edilen gÃ¼Ã§lÃ¼ model)
        - 120 saniye timeout sÃ¼resi
        - LangChain mesaj formatÄ±nÄ± Ollama formatÄ±na Ã§evirir
        - TÃ¼rkÃ§e ve anlamlÄ± yanÄ±tlar alÄ±r
        - MCP tool calling iÃ§in optimize edilmiÅŸ
        
        Args:
            messages: LangChain mesaj listesi (SystemMessage, HumanMessage, AIMessage)
            
        Returns:
            str: Ollama'dan gelen yanÄ±t metni
            
        Son GÃ¼ncellemeler (2025-09-16):
        - ngrok ile host edilen remote Ollama servisi entegrasyonu
        - Model upgrade: llama3.2:1b â†’ llama3.2:3b (daha gÃ¼Ã§lÃ¼ analiz)
        - Timeout artÄ±rÄ±ldÄ±: 30s â†’ 120s
        - GerÃ§ek LLM Ã§aÄŸrÄ±larÄ± baÅŸarÄ±yla Ã§alÄ±ÅŸÄ±yor
        - MCP tool calling performansÄ± artÄ±rÄ±ldÄ±
        """
        try:
            import requests
            
            # LangChain mesajlarÄ±nÄ± Ollama formatÄ±na Ã§evir
            ollama_messages = []
            for msg in messages:
                if hasattr(msg, 'content'):
                    if msg.__class__.__name__ == 'SystemMessage':
                        ollama_messages.append({"role": "system", "content": msg.content})
                    elif msg.__class__.__name__ == 'HumanMessage':
                        ollama_messages.append({"role": "user", "content": msg.content})
                    elif msg.__class__.__name__ == 'AIMessage':
                        ollama_messages.append({"role": "assistant", "content": msg.content})
            
            # Ollama API'sine istek gÃ¶nder
            response = requests.post(
                f"{self.ollama_base_url}/api/chat",
                json={
                    "model": self.ollama_model,
                    "messages": ollama_messages,
                    "stream": False,
                    "options": {
                        "temperature": 0.1,
                        "num_ctx": 2048
                    }
                },
                timeout=120  # Timeout'u 2 dakikaya Ã§Ä±kar
            )
            
            if response.status_code == 200:
                result = response.json()
                return result.get("message", {}).get("content", "")
            else:
                print(f"âŒ Ollama API hatasÄ±: {response.status_code} - {response.text}")
                return "Ollama API hatasÄ±"
                
        except Exception as e:
            print(f"âŒ Manuel Ollama Ã§aÄŸrÄ±sÄ± hatasÄ±: {e}")
            return "Manuel Ollama Ã§aÄŸrÄ±sÄ± baÅŸarÄ±sÄ±z"
    
    def _call_mcp_tool(self, path: str, payload: Dict[str, Any]) -> Dict[str, Any]:
        """
        MCP aracÄ±nÄ± Ã§aÄŸÄ±rÄ±r - DETAYLI LOGGING Ä°LE
        
        ğŸ”¥ Ã–NEMLÄ°: Bu metod LangGraph agent'larÄ±nÄ±n MCP Finance Tools ile iletiÅŸim kurmasÄ±nÄ± saÄŸlar
        Her tool Ã§aÄŸrÄ±sÄ± detaylÄ± olarak loglanÄ±r ve sonuÃ§larÄ± takip edilir
        
        Args:
            path: AraÃ§ yolu (Ã¶rn: "userProfile.get", "market.quotes")
            payload: GÃ¶nderilecek veri
            
        Returns:
            Dict[str, Any]: AraÃ§ yanÄ±tÄ±
        """
        print(f"ğŸŒ MCP Tool Ã‡aÄŸrÄ±sÄ±: {path}")
        print(f"ğŸ“¥ Payload: {payload}")
        
        try:
            result = service_manager.mcp_service.call_tool(path, payload)
            print(f"âœ… MCP Tool BaÅŸarÄ±lÄ±: {path}")
            print(f"ğŸ“¤ SonuÃ§: {str(result)[:300]}...")
            return result
        except Exception as e:
            print(f"âŒ MCP Tool HatasÄ±: {path} - {e}")
            return {"error": str(e), "path": path}
    
    def _get_short_term_memory(self, userId: str) -> str:
        """
        Redis'ten kÄ±sa vadeli hafÄ±zayÄ± alÄ±r
        
        Args:
            userId: KullanÄ±cÄ± ID'si
            
        Returns:
            str: KÄ±sa vadeli hafÄ±za bilgisi
        """
        last_action = service_manager.redis_service.get_user_action(userId)
        if last_action:
            return f"Son kullanÄ±cÄ± eylemi: {last_action}"
        return ""
    
    def _get_long_term_memory(self, userId: str, query: str) -> str:
        """
        Qdrant'tan uzun vadeli hafÄ±zayÄ± alÄ±r
        
        Args:
            userId: KullanÄ±cÄ± ID'si
            query: Arama sorgusu
            
        Returns:
            str: Uzun vadeli hafÄ±za bilgisi
        """
        try:
            similar_memories = service_manager.qdrant_service.search_similar(
                userId, query, top_k=3
            )
            
            if similar_memories:
                memory_texts = [
                    f"- {mem['payload'].get('content', '')[:100]}..." 
                    for mem in similar_memories
                ]
                return f"GeÃ§miÅŸ benzer analizler:\n" + "\n".join(memory_texts)
            return ""
        except Exception as e:
            print(f"âš ï¸ Uzun vadeli hafÄ±za hatasÄ±: {e}")
            return ""
    
    def _build_coordinator_prompt(self, userId: str, amount: int, state: FinancialState, 
                                short_term_memory: str, long_term_memory: str) -> str:
        """
        Coordinator agent iÃ§in kapsamlÄ± prompt oluÅŸturur
        
        Args:
            userId: KullanÄ±cÄ± ID'si
            amount: MaaÅŸ miktarÄ±
            state: Workflow state'i
            short_term_memory: KÄ±sa vadeli hafÄ±za
            long_term_memory: Uzun vadeli hafÄ±za
            
        Returns:
            str: Coordinator prompt'u
        """
        return f"""
KullanÄ±cÄ± {userId} iÃ§in {amount:,}â‚º maaÅŸ yatÄ±ÅŸÄ± analizi:

PaymentsAgent: {state['payments_output'].get('message', 'N/A')}
RiskAgent: {state['risk_output'].get('message', 'N/A')}
InvestmentAgent: {state['investment_output'].get('message', 'N/A')}

Short-term memory: {short_term_memory}
Long-term memory: {long_term_memory}

Bu bilgileri kullanarak kullanÄ±cÄ±ya kiÅŸiselleÅŸtirilmiÅŸ, samimi ve net bir Ã¶neri mesajÄ± oluÅŸtur.
"""
    
    def _get_coordinator_system_prompt(self) -> str:
        """
        Coordinator agent iÃ§in system prompt dÃ¶ndÃ¼rÃ¼r
        
        Returns:
            str: System prompt
        """
        return """Sen bir finansal danÄ±ÅŸmansÄ±n. KullanÄ±cÄ±ya samimi, gÃ¼venilir ve kiÅŸiselleÅŸtirilmiÅŸ tavsiyeler veriyorsun. 

GÃ¶revlerin:
1. KullanÄ±cÄ±nÄ±n finansal durumunu analiz et
2. Risk profiline gÃ¶re uygun Ã¶neriler sun
3. GeÃ§miÅŸ tercihlerini dikkate al
4. Net ve anlaÅŸÄ±lÄ±r bir dil kullan
5. KullanÄ±cÄ±ya gÃ¼ven veren bir ton kullan

TÃ¼rkÃ§e yanÄ±t ver ve finansal terimleri aÃ§Ä±kla."""
    
    def _update_memories(self, userId: str, amount: int, correlationId: str, final_message: str):
        """
        HafÄ±zalarÄ± gÃ¼nceller
        
        Args:
            userId: KullanÄ±cÄ± ID'si
            amount: MaaÅŸ miktarÄ±
            correlationId: Ä°ÅŸlem takip ID'si
            final_message: Final mesaj
        """
        try:
            # Uzun vadeli hafÄ±zayÄ± gÃ¼ncelle (Qdrant)
            service_manager.qdrant_service.store_memory(
                user_id=userId,
                content=f"Deposit analysis for {amount}â‚º: {final_message}",
                metadata={
                    "type": "deposit_analysis",
                    "amount": amount,
                    "correlationId": correlationId
                }
            )
            print(f"âœ… Uzun vadeli hafÄ±za gÃ¼ncellendi: {userId}")
        except Exception as e:
            print(f"âš ï¸ Uzun vadeli hafÄ±za gÃ¼ncelleme hatasÄ±: {e}")
        
        # KÄ±sa vadeli hafÄ±zayÄ± gÃ¼ncelle (Redis)
        try:
            service_manager.redis_service.push_user_event(userId, {
                "type": "deposit",
                "amount": amount,
                "ts": int(time.time()),
                "message": final_message
            })
            print(f"âœ… KÄ±sa vadeli hafÄ±za gÃ¼ncellendi: {userId}")
        except Exception as e:
            print(f"âš ï¸ KÄ±sa vadeli hafÄ±za gÃ¼ncelleme hatasÄ±: {e}")
    
    def run(self, initial_state: FinancialState) -> Optional[FinancialState]:
        """
        Workflow'u Ã§alÄ±ÅŸtÄ±rÄ±r (execute metodunun alias'Ä±)
        
        Args:
            initial_state: BaÅŸlangÄ±Ã§ state'i
            
        Returns:
            FinancialState: Workflow sonucu
        """
        return self.execute(initial_state)
    
    
    def is_ready(self) -> bool:
        """
        Workflow'un hazÄ±r olup olmadÄ±ÄŸÄ±nÄ± kontrol eder
        
        Returns:
            bool: HazÄ±r ise True
        """
        return self.workflow is not None


# LangGraph Tools - MCP Finance Tools iÃ§in
@tool
def transactions_query(userId: str, since: str = None, limit: int = 10) -> dict:
    """
    KullanÄ±cÄ± iÅŸlemlerini sorgular
    
    Args:
        userId: KullanÄ±cÄ± ID'si
        since: BaÅŸlangÄ±Ã§ tarihi (opsiyonel)
        limit: Maksimum sonuÃ§ sayÄ±sÄ±
        
    Returns:
        dict: Ä°ÅŸlem listesi
    """
    return service_manager.mcp_service.call_tool("transactions.query", {
        "userId": userId, 
        "since": since, 
        "limit": limit
    })


@tool
def userProfile_get(userId: str) -> dict:
    """
    KullanÄ±cÄ± profilini ve tercihlerini getirir
    
    Args:
        userId: KullanÄ±cÄ± ID'si
        
    Returns:
        dict: KullanÄ±cÄ± profili
    """
    return service_manager.mcp_service.call_tool("userProfile.get", {"userId": userId})


@tool
def risk_scoreTransaction(userId: str, tx: dict) -> dict:
    """
    Ä°ÅŸlem risk skorunu hesaplar
    
    Args:
        userId: KullanÄ±cÄ± ID'si
        tx: Ä°ÅŸlem bilgileri
        
    Returns:
        dict: Risk analizi
    """
    return service_manager.mcp_service.call_tool("risk.scoreTransaction", {
        "userId": userId, 
        "tx": tx
    })


@tool
def market_quotes(assetType: str, tenor: str = "1Y") -> dict:
    """
    YatÄ±rÄ±m Ã¼rÃ¼nleri iÃ§in piyasa kotalarÄ±nÄ± getirir
    
    Args:
        assetType: VarlÄ±k tÃ¼rÃ¼ (bond, equity, fund, savings)
        tenor: Vade sÃ¼resi
        
    Returns:
        dict: Piyasa kotalarÄ±
    """
    return service_manager.mcp_service.call_tool("market.quotes", {
        "assetType": assetType, 
        "tenor": tenor
    })


@tool
def savings_createTransfer(userId: str, fromAccount: str, toSavingsId: str, amount: int) -> dict:
    """
    Tasarruf transferi oluÅŸturur
    
    Args:
        userId: KullanÄ±cÄ± ID'si
        fromAccount: Kaynak hesap
        toSavingsId: Hedef tasarruf hesabÄ±
        amount: Transfer miktarÄ±
        
    Returns:
        dict: Transfer sonucu
    """
    return service_manager.mcp_service.call_tool("savings.createTransfer", {
        "userId": userId,
        "fromAccount": fromAccount,
        "toSavingsId": toSavingsId,
        "amount": amount
    })
